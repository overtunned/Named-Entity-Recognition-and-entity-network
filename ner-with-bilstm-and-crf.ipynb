{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-01T07:30:19.614612Z","iopub.execute_input":"2021-06-01T07:30:19.614916Z","iopub.status.idle":"2021-06-01T07:30:20.156117Z","shell.execute_reply.started":"2021-06-01T07:30:19.614864Z","shell.execute_reply":"2021-06-01T07:30:20.155330Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/entity-annotated-corpus/ner.csv\n/kaggle/input/entity-annotated-corpus/ner_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/input/entity-annotated-corpus/ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)\ndf.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-06-01T07:30:20.157865Z","iopub.execute_input":"2021-06-01T07:30:20.158315Z","iopub.status.idle":"2021-06-01T07:30:25.574543Z","shell.execute_reply.started":"2021-06-01T07:30:20.158264Z","shell.execute_reply":"2021-06-01T07:30:25.573546Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"b'Skipping line 281837: expected 25 fields, saw 34\\n'\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n0           0  thousand         of        demonstr           NNS   \n1           1        of   demonstr            have           VBP   \n2           2  demonstr       have           march           VBN   \n3           3      have      march         through            IN   \n4           4     march    through          london           NNP   \n\n  next-next-shape next-next-word next-pos next-shape      next-word  ...  \\\n0       lowercase  demonstrators       IN  lowercase             of  ...   \n1       lowercase           have      NNS  lowercase  demonstrators  ...   \n2       lowercase        marched      VBP  lowercase           have  ...   \n3       lowercase        through      VBN  lowercase        marched  ...   \n4     capitalized         London       IN  lowercase        through  ...   \n\n  prev-prev-lemma prev-prev-pos prev-prev-shape prev-prev-word   prev-shape  \\\n0      __start2__    __START2__        wildcard     __START2__     wildcard   \n1      __start1__    __START1__        wildcard     __START1__  capitalized   \n2        thousand           NNS     capitalized      Thousands    lowercase   \n3              of            IN       lowercase             of    lowercase   \n4        demonstr           NNS       lowercase  demonstrators    lowercase   \n\n       prev-word sentence_idx        shape           word tag  \n0     __START1__          1.0  capitalized      Thousands   O  \n1      Thousands          1.0    lowercase             of   O  \n2             of          1.0    lowercase  demonstrators   O  \n3  demonstrators          1.0    lowercase           have   O  \n4           have          1.0    lowercase        marched   O  \n\n[5 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>lemma</th>\n      <th>next-lemma</th>\n      <th>next-next-lemma</th>\n      <th>next-next-pos</th>\n      <th>next-next-shape</th>\n      <th>next-next-word</th>\n      <th>next-pos</th>\n      <th>next-shape</th>\n      <th>next-word</th>\n      <th>...</th>\n      <th>prev-prev-lemma</th>\n      <th>prev-prev-pos</th>\n      <th>prev-prev-shape</th>\n      <th>prev-prev-word</th>\n      <th>prev-shape</th>\n      <th>prev-word</th>\n      <th>sentence_idx</th>\n      <th>shape</th>\n      <th>word</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>thousand</td>\n      <td>of</td>\n      <td>demonstr</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>demonstrators</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>...</td>\n      <td>__start2__</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START2__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>1.0</td>\n      <td>capitalized</td>\n      <td>Thousands</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>of</td>\n      <td>demonstr</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>lowercase</td>\n      <td>have</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>demonstrators</td>\n      <td>...</td>\n      <td>__start1__</td>\n      <td>__START1__</td>\n      <td>wildcard</td>\n      <td>__START1__</td>\n      <td>capitalized</td>\n      <td>Thousands</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>demonstr</td>\n      <td>have</td>\n      <td>march</td>\n      <td>VBN</td>\n      <td>lowercase</td>\n      <td>marched</td>\n      <td>VBP</td>\n      <td>lowercase</td>\n      <td>have</td>\n      <td>...</td>\n      <td>thousand</td>\n      <td>NNS</td>\n      <td>capitalized</td>\n      <td>Thousands</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>demonstrators</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>have</td>\n      <td>march</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>through</td>\n      <td>VBN</td>\n      <td>lowercase</td>\n      <td>marched</td>\n      <td>...</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>of</td>\n      <td>lowercase</td>\n      <td>demonstrators</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>have</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>march</td>\n      <td>through</td>\n      <td>london</td>\n      <td>NNP</td>\n      <td>capitalized</td>\n      <td>London</td>\n      <td>IN</td>\n      <td>lowercase</td>\n      <td>through</td>\n      <td>...</td>\n      <td>demonstr</td>\n      <td>NNS</td>\n      <td>lowercase</td>\n      <td>demonstrators</td>\n      <td>lowercase</td>\n      <td>have</td>\n      <td>1.0</td>\n      <td>lowercase</td>\n      <td>marched</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = df[['sentence_idx','word','tag']]\n\ndata.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T07:30:25.576631Z","iopub.execute_input":"2021-06-01T07:30:25.577059Z","iopub.status.idle":"2021-06-01T07:30:25.608428Z","shell.execute_reply.started":"2021-06-01T07:30:25.576980Z","shell.execute_reply":"2021-06-01T07:30:25.607785Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"    sentence_idx           word    tag\n0            1.0      Thousands      O\n1            1.0             of      O\n2            1.0  demonstrators      O\n3            1.0           have      O\n4            1.0        marched      O\n5            1.0        through      O\n6            1.0         London  B-geo\n7            1.0             to      O\n8            1.0        protest      O\n9            1.0            the      O\n10           1.0            war      O\n11           1.0             in      O\n12           1.0           Iraq  B-geo\n13           1.0            and      O\n14           1.0         demand      O\n15           1.0            the      O\n16           1.0     withdrawal      O\n17           1.0             of      O\n18           1.0        British  B-gpe\n19           1.0         troops      O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_idx</th>\n      <th>word</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>Thousands</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>of</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>demonstrators</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>have</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>marched</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>through</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.0</td>\n      <td>London</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.0</td>\n      <td>to</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.0</td>\n      <td>protest</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.0</td>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.0</td>\n      <td>war</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.0</td>\n      <td>in</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.0</td>\n      <td>Iraq</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.0</td>\n      <td>and</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.0</td>\n      <td>demand</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.0</td>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1.0</td>\n      <td>withdrawal</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1.0</td>\n      <td>of</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1.0</td>\n      <td>British</td>\n      <td>B-gpe</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1.0</td>\n      <td>troops</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['tag'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T07:30:25.609946Z","iopub.execute_input":"2021-06-01T07:30:25.610392Z","iopub.status.idle":"2021-06-01T07:30:25.792078Z","shell.execute_reply.started":"2021-06-01T07:30:25.610197Z","shell.execute_reply":"2021-06-01T07:30:25.790694Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"O        889973\nB-geo     37525\nB-tim     20193\nB-org     20184\nI-per     17382\nB-per     17011\nI-org     16537\nB-gpe     16392\nI-geo      7409\nI-tim      6298\nB-art       434\nB-eve       348\nI-eve       297\nI-art       280\nI-gpe       229\nB-nat       226\nI-nat        76\nName: tag, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"class SentenceGetter(object):\n    \n    def __init__(self, dataset):\n        self.n_sent = 1\n        self.dataset = dataset\n        self.empty = False\n        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n                                                        s[\"tag\"].values.tolist())]\n        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n        self.sentences = [s for s in self.grouped]\n    \n    def get_next(self):\n        try:\n            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n            self.n_sent += 1\n            return s\n        except:\n            return None\n          \ngetter = SentenceGetter(data)\nsentences = getter.sentences","metadata":{"execution":{"iopub.status.busy":"2021-06-01T07:30:25.796075Z","iopub.execute_input":"2021-06-01T07:30:25.796307Z","iopub.status.idle":"2021-06-01T07:30:28.907896Z","shell.execute_reply.started":"2021-06-01T07:30:25.796262Z","shell.execute_reply":"2021-06-01T07:30:28.906866Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(sentences[1:3])","metadata":{"execution":{"iopub.status.busy":"2021-06-01T07:30:28.909971Z","iopub.execute_input":"2021-06-01T07:30:28.910261Z","iopub.status.idle":"2021-06-01T07:30:28.916426Z","shell.execute_reply.started":"2021-06-01T07:30:28.910215Z","shell.execute_reply":"2021-06-01T07:30:28.915388Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[[('Families', 'O'), ('of', 'O'), ('soldiers', 'O'), ('killed', 'O'), ('in', 'O'), ('the', 'O'), ('conflict', 'O'), ('joined', 'O'), ('the', 'O'), ('protesters', 'O'), ('who', 'O'), ('carried', 'O'), ('banners', 'O'), ('with', 'O'), ('such', 'O'), ('slogans', 'O'), ('as', 'O'), ('\"', 'O'), ('Bush', 'B-per'), ('Number', 'O'), ('One', 'O'), ('Terrorist', 'O'), ('\"', 'O'), ('and', 'O'), ('\"', 'O'), ('Stop', 'O'), ('the', 'O'), ('Bombings', 'O'), ('.', 'O'), ('\"', 'O'), ('Families', 'O'), ('of', 'O'), ('soldiers', 'O'), ('killed', 'O'), ('in', 'O'), ('the', 'O'), ('conflict', 'O'), ('joined', 'O'), ('the', 'O'), ('protesters', 'O'), ('who', 'O'), ('carried', 'O'), ('banners', 'O'), ('with', 'O'), ('such', 'O'), ('slogans', 'O'), ('as', 'O'), ('\"', 'O'), ('Bush', 'B-per'), ('Number', 'O'), ('One', 'O'), ('Terrorist', 'O'), ('\"', 'O'), ('and', 'O'), ('\"', 'O'), ('Stop', 'O'), ('the', 'O'), ('Bombings', 'O'), ('.', 'O'), ('\"', 'O')], [('They', 'O'), ('marched', 'O'), ('from', 'O'), ('the', 'O'), ('Houses', 'O'), ('of', 'O'), ('Parliament', 'O'), ('to', 'O'), ('a', 'O'), ('rally', 'O'), ('in', 'O'), ('Hyde', 'B-geo'), ('Park', 'I-geo'), ('.', 'O'), ('They', 'O'), ('marched', 'O'), ('from', 'O'), ('the', 'O'), ('Houses', 'O'), ('of', 'O'), ('Parliament', 'O'), ('to', 'O'), ('a', 'O'), ('rally', 'O'), ('in', 'O'), ('Hyde', 'B-geo'), ('Park', 'I-geo'), ('.', 'O')]]\n","output_type":"stream"}]},{"cell_type":"code","source":"from math import nan\n\nwords = list(set(data[\"word\"].values))\nn_words = len(words)\n\ntags = []\nfor tag in set(data[\"tag\"].values):\n    if tag is nan or isinstance(tag, float):\n        tags.append('unk')\n    else:\n        tags.append(tag)\nn_tags = len(tags)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T07:30:28.918220Z","iopub.execute_input":"2021-06-01T07:30:28.918841Z","iopub.status.idle":"2021-06-01T07:30:29.031469Z","shell.execute_reply.started":"2021-06-01T07:30:28.918474Z","shell.execute_reply":"2021-06-01T07:30:29.030836Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from future.utils import iteritems\n\nword2idx = {w: i for i, w in enumerate(words)}\ntag2idx = {t: i for i, t in enumerate(tags)}\nidx2tag = {v: k for k, v in iteritems(tag2idx)}\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T07:30:29.032841Z","iopub.execute_input":"2021-06-01T07:30:29.033771Z","iopub.status.idle":"2021-06-01T07:30:29.054854Z","shell.execute_reply.started":"2021-06-01T07:30:29.033222Z","shell.execute_reply":"2021-06-01T07:30:29.054222Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nmaxlen = max([len(s) for s in sentences])\n\nX = [[word2idx[w[0]] for w in s] for s in sentences]\nX = pad_sequences(maxlen=maxlen, sequences=X, padding=\"post\",value=n_words - 1)\n\ny = [[tag2idx[w[1]] for w in s] for s in sentences]\ny = pad_sequences(maxlen=maxlen, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\ny = [to_categorical(i, num_classes=n_tags) for i in y]\n\n# Split train and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T07:30:29.056417Z","iopub.execute_input":"2021-06-01T07:30:29.056860Z","iopub.status.idle":"2021-06-01T07:30:37.009808Z","shell.execute_reply.started":"2021-06-01T07:30:29.056674Z","shell.execute_reply":"2021-06-01T07:30:37.008846Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install git+https://www.github.com/keras-team/keras-contrib.git","metadata":{"execution":{"iopub.status.busy":"2021-06-01T07:30:37.011110Z","iopub.execute_input":"2021-06-01T07:30:37.011401Z","iopub.status.idle":"2021-06-01T07:30:46.995969Z","shell.execute_reply.started":"2021-06-01T07:30:37.011354Z","shell.execute_reply":"2021-06-01T07:30:46.995100Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting git+https://www.github.com/keras-team/keras-contrib.git\n  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-_gf6aabf\n  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-_gf6aabf\nRequirement already satisfied: keras in /opt/conda/lib/python3.6/site-packages (from keras-contrib==2.0.8) (2.3.1)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.17.4)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (5.1.2)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.13.0)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.3.3)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (2.9.0)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.1.0)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras->keras-contrib==2.0.8) (1.0.8)\nBuilding wheels for collected packages: keras-contrib\n  Building wheel for keras-contrib (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101065 sha256=5f0b8dda5db6202b8314f27271a39a3a2714a7e481adf246c759475434dc504d\n  Stored in directory: /tmp/pip-ephem-wheel-cache-_9fqkesz/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\nSuccessfully built keras-contrib\nInstalling collected packages: keras-contrib\nSuccessfully installed keras-contrib-2.0.8\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.models import Model, Input\nfrom keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\nimport keras as k\nfrom keras_contrib.layers import CRF\n\ninput = Input(shape=(140,))\nword_embedding_size = 150\n\n# Embedding Layer\nmodel = Embedding(input_dim=n_words, output_dim=word_embedding_size, input_length=140)(input)\n\n# BI-LSTM Layer\nmodel = Bidirectional(LSTM(units=word_embedding_size, \n                           return_sequences=True, \n                           dropout=0.5, \n                           recurrent_dropout=0.5, \n                           kernel_initializer=k.initializers.he_normal()))(model)\nmodel = LSTM(units=word_embedding_size * 2, \n             return_sequences=True, \n             dropout=0.5, \n             recurrent_dropout=0.5, \n             kernel_initializer=k.initializers.he_normal())(model)\n\n# TimeDistributed Layer\nmodel = TimeDistributed(Dense(n_tags, activation=\"relu\"))(model)  \n\n# CRF Layer\ncrf = CRF(n_tags)\n\nout = crf(model)  # output\nmodel = Model(input, out)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T07:30:46.999886Z","iopub.execute_input":"2021-06-01T07:30:47.000117Z","iopub.status.idle":"2021-06-01T07:30:50.574939Z","shell.execute_reply.started":"2021-06-01T07:30:47.000073Z","shell.execute_reply":"2021-06-01T07:30:50.574163Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt\n\n#Optimiser \nadam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n\n# Compile model\nmodel.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n\nmodel.summary()\n\n# Saving the best model only\nfilepath=\"ner-bi-lstm-td-model-{val_accuracy:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\n# Fit the best model\nhistory = model.fit(X_train, np.array(y_train), batch_size=256, epochs=20, validation_split=0.1, verbose=1, callbacks=callbacks_list)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T07:30:50.576321Z","iopub.execute_input":"2021-06-01T07:30:50.576595Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n  warnings.warn('CRF.loss_function is deprecated '\n/opt/conda/lib/python3.6/site-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n  warnings.warn('CRF.accuracy is deprecated and it '\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 140)               0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 140, 150)          4525950   \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 140, 300)          361200    \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 140, 300)          721200    \n_________________________________________________________________\ntime_distributed_1 (TimeDist (None, 140, 18)           5418      \n_________________________________________________________________\ncrf_1 (CRF)                  (None, 140, 18)           702       \n=================================================================\nTotal params: 5,614,470\nTrainable params: 5,614,470\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","output_type":"stream"},{"name":"stdout","text":"Train on 25326 samples, validate on 2815 samples\nEpoch 1/20\n22784/25326 [=========================>....] - ETA: 5s - loss: 0.6858 - crf_viterbi_accuracy: 0.8517 - accuracy: 4.4517e-05","output_type":"stream"}]},{"cell_type":"code","source":"# Plot the graph \nplt.style.use('ggplot')\n\ndef plot_history(history):\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    x = range(1, len(accuracy) + 1)\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(x, accuracy, 'b', label='Training acc')\n    plt.plot(x, val_accuracy, 'r', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.subplot(1, 2, 2)\n    plt.plot(x, loss, 'b', label='Training loss')\n    plt.plot(x, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\nplot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred2label(pred):\n    out = []\n    for pred_i in pred:\n        out_i = []\n        for p in pred_i:\n            p_i = np.argmax(p)\n            out_i.append(idx2tag[p_i])\n        out.append(out_i)\n    return out\ntest_pred = model.predict(X_test, verbose=1)   \npred_labels = pred2label(test_pred)\ntest_labels = pred2label(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install seqeval","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\nprint(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install sklearn_crfsuite","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from  sklearn_crfsuite.metrics import flat_classification_report  \nreport = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\nprint(report)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TP = {}\nTN = {}\nFP = {}\nFN = {}\nfor tag in tag2idx.keys():\n    TP[tag] = 0\n    TN[tag] = 0    \n    FP[tag] = 0    \n    FN[tag] = 0    \n\ndef accumulate_score_by_tag(gt, pred):\n    \"\"\"\n    For each tag keep stats\n    \"\"\"\n    if gt == pred:\n        TP[gt] += 1\n    elif gt != 'O' and pred == 'O':\n        FN[gt] +=1\n    elif gt == 'O' and pred != 'O':\n        FP[gt] += 1\n    else:\n        TN[gt] += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, sentence in enumerate(X_test):\n    y_hat = np.argmax(test_pred[0], axis=-1)\n    gt = np.argmax(y_test[0], axis=-1)\n    for idx, (w,pred) in enumerate(zip(sentence,y_hat)):\n        accumulate_score_by_tag(idx2tag[gt[idx]],tags[pred])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for tag in tag2idx.keys():\n    print(f'tag:{tag}')    \n    print('\\t TN:{:10}\\tFP:{:10}'.format(TN[tag],FP[tag]))\n    print('\\t FN:{:10}\\tTP:{:10}'.format(FN[tag],TP[tag]))    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}